{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPKOKpPpNQDdHSKomIbOOLm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steveregis/eat-right/blob/main/EatBuddy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EatBuddy\n",
        "\n",
        "Random pilot to test if we can create a intelligent chatbot that can provide personalized advise on allergies found in a given menu\n"
      ],
      "metadata": {
        "id": "2UDG2XmB7WGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.35.0 accelerate bitsandbytes\n",
        "!pip install huggingface_hub>=0.14.1\n",
        "!apt-get update && apt-get install -y g++ cmake libssl-dev\n",
        "!pip install auto-gptq\n",
        "!pip install transformers accelerate"
      ],
      "metadata": {
        "id": "aNb5gXi07d36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade huggingface_hub accelerate"
      ],
      "metadata": {
        "id": "PSxwXsfD8uwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, pipeline\n",
        "from auto_gptq import AutoGPTQForCausalLM  # Correct GPTQ loader\n",
        "\n",
        "model_id = \"TheBloke/Llama-2-13B-chat-GPTQ\"\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
        "\n",
        "# Load the GPTQ model\n",
        "model = AutoGPTQForCausalLM.from_quantized(model_id, device=\"cuda:0\", use_safetensors=True)\n",
        "\n",
        "# Create a text-generation pipeline\n",
        "llama_pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")\n",
        "\n",
        "# Test the pipeline\n",
        "result = llama_pipe(\"Hello, how are you?\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "EmgszHMI8iRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(prompt, max_length=6144, pipe=llama_pipe, **kwargs):\n",
        "    \"\"\"\n",
        "def generate(prompt, max_length=4096, pipe=llama_pipe, **kwargs):\n",
        "\n",
        "    Generates a response to the given prompt using a specified language model pipeline.\n",
        "\n",
        "    This function takes a prompt and passes it to a language model pipeline, such as LLaMA,\n",
        "    to generate a text response. The function is designed to allow customization of the\n",
        "    generation process through various parameters and keyword arguments.\n",
        "\n",
        "    Parameters:\n",
        "    - prompt (str): The input text prompt to generate a response for.\n",
        "    - max_length (int): The maximum length of the generated response. Default is 1024 tokens.\n",
        "    - pipe (callable): The language model pipeline function used for generation. Default is llama_pipe.\n",
        "    - **kwargs: Additional keyword arguments that are passed to the pipeline function.\n",
        "\n",
        "    Returns:\n",
        "    - str: The generated text response from the model, trimmed of leading and trailing whitespace.\n",
        "\n",
        "    Example usage:\n",
        "    ```\n",
        "    prompt_text = \"Explain the theory of relativity.\"\n",
        "    response = generate(prompt_text, max_length=512, pipe=my_custom_pipeline, temperature=0.7)\n",
        "    print(response)\n",
        "    ```\n",
        "    \"\"\"\n",
        "\n",
        "    def_kwargs = dict(return_full_text=False, return_dict=False)\n",
        "    response = pipe(prompt.strip(), max_length=max_length, **kwargs, **def_kwargs)\n",
        "    return response[0]['generated_text'].strip()"
      ],
      "metadata": {
        "id": "sbOMX-G_-Lsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def construct_prompt_with_context(main_prompt, system_context=\"\", conversation_examples=[]):\n",
        "    \"\"\"\n",
        "    Constructs a complete structured prompt for a language model, including optional system context and conversation examples.\n",
        "\n",
        "    This function compiles a prompt that can be directly used for generating responses from a language model.\n",
        "    It creates a structured format that begins with an optional system context message, appends a series of conversational\n",
        "    examples as prior interactions, and ends with the main user prompt. If no system context or conversation examples are provided,\n",
        "    it will return only the main prompt.\n",
        "\n",
        "    Parameters:\n",
        "    - main_prompt (str): The core question or statement for the language model to respond to.\n",
        "    - system_context (str, optional): Additional context or information about the scenario or environment. Defaults to an empty string.\n",
        "    - conversation_examples (list of tuples, optional): Prior exchanges provided as context, where each tuple contains a user message\n",
        "      and a corresponding agent response. Defaults to an empty list.\n",
        "\n",
        "    Returns:\n",
        "    - str: A string formatted as a complete prompt ready for language model input. If no system context or examples are provided, returns the main prompt.\n",
        "\n",
        "    Example usage:\n",
        "    ```\n",
        "    main_prompt = \"I'm looking to improve my dialogue writing skills for my next short story. Any suggestions?\"\n",
        "    system_context = \"User is an aspiring author seeking to enhance dialogue writing techniques.\"\n",
        "    conversation_examples = [\n",
        "        (\"How can dialogue contribute to character development?\", \"Dialogue should reveal character traits and show personal growth over the story arc.\"),\n",
        "        (\"What are some common pitfalls in writing dialogue?\", \"Avoid exposition dumps in dialogue and make sure each character's voice is distinct.\")\n",
        "    ]\n",
        "\n",
        "    full_prompt = construct_prompt_with_context(main_prompt, system_context, conversation_examples)\n",
        "    print(full_prompt)\n",
        "    ```\n",
        "    \"\"\"\n",
        "\n",
        "    # Return the main prompt if no system context or conversation examples are provided\n",
        "    if not system_context and not conversation_examples:\n",
        "        return main_prompt\n",
        "\n",
        "    # Start with the initial part of the prompt including the system context, if provided\n",
        "    full_prompt = f\"<s>[INST] <<SYS>>{system_context}<</SYS>>\\n\" if system_context else \"<s>[INST]\\n\"\n",
        "\n",
        "    # Add each example from the conversation_examples to the prompt\n",
        "    for user_msg, agent_response in conversation_examples:\n",
        "        full_prompt += f\"{user_msg} [/INST] {agent_response} </s><s>[INST]\"\n",
        "\n",
        "    # Add the main user prompt at the end\n",
        "    full_prompt += f\"{main_prompt} [/INST]\"\n",
        "\n",
        "    return full_prompt"
      ],
      "metadata": {
        "id": "CJOmqWcz_YuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_token_count(text, tokenizer):\n",
        "    \"\"\"\n",
        "    Calculate and return the number of tokens in a given text using a specified tokenizer.\n",
        "\n",
        "    This function takes a string of text and a tokenizer. It uses the tokenizer to encode the text\n",
        "    into tokens and then returns the count of these tokens.\n",
        "\n",
        "    Parameters:\n",
        "    - text (str): The input string to be tokenized.\n",
        "    - tokenizer: A tokenizer instance capable of encoding text into tokens.\n",
        "\n",
        "    Returns:\n",
        "    - int: The number of tokens in the input text as determined by the tokenizer.\n",
        "    \"\"\"\n",
        "    return len(tokenizer.encode(text))"
      ],
      "metadata": {
        "id": "Vmr7fMadLjRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def concat_history(tuples_list):\n",
        "    \"\"\"\n",
        "    Concatenates texts from a list of 2-tuples.\n",
        "\n",
        "    Each tuple in the list is expected to contain two strings. The function\n",
        "    will concatenate all the first elements followed by all the second elements\n",
        "    in their respective order of appearance in the list.\n",
        "\n",
        "    Parameters:\n",
        "    - tuples_list (list of 2-tuples): A list where each element is a tuple of two strings.\n",
        "\n",
        "    Returns:\n",
        "    - str: A single string that is the result of concatenating all the texts from the tuples.\n",
        "\n",
        "    Example usage:\n",
        "    ```\n",
        "    conversation_tuples = [\n",
        "        ('Question 1', 'Answer 1'),\n",
        "        ('Question 2', 'Answer 2'),\n",
        "        ('Question 3', 'Answer 3')\n",
        "    ]\n",
        "\n",
        "    concatenated_text = concatenate_texts_from_tuples(conversation_tuples)\n",
        "    print(concatenated_text)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    # Concatenate all the first and second elements of the tuples\n",
        "    return ''.join(question + response for question, response in tuples_list)"
      ],
      "metadata": {
        "id": "awmZIqAFLng9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "menu= [\n",
        "    {\n",
        "      \"name\": \"Hummus\",\n",
        "      \"ingredients\": [\"Chickpeas\", \"Tahini\", \"Olive oil\", \"Lemon juice\", \"Garlic\", \"Cumin\", \"Salt\"],\n",
        "      \"allergies\": {\n",
        "        \"Sesame\": {\n",
        "          \"related_ingredient\": \"Tahini\",\n",
        "          \"possible_symptoms\": [\"Hives\", \"Swelling\", \"Difficulty breathing\", \"Gastrointestinal issues\"],\n",
        "          \"caution\": \"Avoid if you have a sesame allergy.\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Falafel\",\n",
        "      \"ingredients\": [\"Chickpeas\", \"Onion\", \"Garlic\", \"Parsley\", \"Cumin\", \"Coriander\", \"Salt\", \"Pepper\", \"Flour\", \"Baking powder\", \"Oil for frying\"],\n",
        "      \"allergies\": {\n",
        "        \"Gluten\": {\n",
        "          \"related_ingredient\": \"Flour\",\n",
        "          \"possible_symptoms\": [\"Bloating\", \"Diarrhea\", \"Fatigue\", \"Headaches\"],\n",
        "          \"caution\": \"Avoid if you have celiac disease or gluten intolerance.\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Tabbouleh\",\n",
        "      \"ingredients\": [\"Parsley\", \"Tomatoes\", \"Onion\", \"Bulgur\", \"Mint\", \"Lemon juice\", \"Olive oil\", \"Salt\"],\n",
        "      \"allergies\": {\n",
        "        \"Gluten\": {\n",
        "          \"related_ingredient\": \"Bulgur\",\n",
        "          \"possible_symptoms\": [\"Bloating\", \"Diarrhea\", \"Fatigue\", \"Headaches\"],\n",
        "          \"caution\": \"Avoid if you have celiac disease or gluten intolerance.\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Shawarma\",\n",
        "      \"ingredients\": [\"Marinated meat (chicken, beef, or lamb)\", \"Garlic\", \"Yogurt\", \"Lemon juice\", \"Spices (cumin, paprika, etc.)\", \"Pita bread\", \"Vegetables (tomato, cucumber, onion)\", \"Tahini or garlic sauce\"],\n",
        "      \"allergies\": {\n",
        "        \"Dairy\": {\n",
        "          \"related_ingredient\": \"Yogurt, Tahini\",\n",
        "          \"possible_symptoms\": [\"Hives\", \"Nausea\", \"Abdominal pain\", \"Anaphylaxis in severe cases\"],\n",
        "          \"caution\": \"Avoid if you have a dairy allergy or lactose intolerance.\"\n",
        "        },\n",
        "        \"Gluten\": {\n",
        "          \"related_ingredient\": \"Pita bread\",\n",
        "          \"possible_symptoms\": [\"Bloating\", \"Diarrhea\", \"Fatigue\", \"Headaches\"],\n",
        "          \"caution\": \"Avoid if you have celiac disease or gluten intolerance.\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Fattoush\",\n",
        "      \"ingredients\": [\"Lettuce\", \"Tomatoes\", \"Cucumbers\", \"Radishes\", \"Green onions\", \"Pita bread\", \"Sumac\", \"Olive oil\", \"Lemon juice\"],\n",
        "      \"allergies\": {\n",
        "        \"Gluten\": {\n",
        "          \"related_ingredient\": \"Pita bread\",\n",
        "          \"possible_symptoms\": [\"Bloating\", \"Diarrhea\", \"Fatigue\", \"Headaches\"],\n",
        "          \"caution\": \"Avoid if you have celiac disease or gluten intolerance.\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Baba Ghanoush\",\n",
        "      \"ingredients\": [\"Eggplant\", \"Tahini\", \"Olive oil\", \"Lemon juice\", \"Garlic\", \"Salt\"],\n",
        "      \"allergies\": {\n",
        "        \"Sesame\": {\n",
        "          \"related_ingredient\": \"Tahini\",\n",
        "          \"possible_symptoms\": [\"Hives\", \"Swelling\", \"Difficulty breathing\", \"Gastrointestinal issues\"],\n",
        "          \"caution\": \"Avoid if you have a sesame allergy.\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Kebabs\",\n",
        "      \"ingredients\": [\"Ground meat (beef, lamb, or chicken)\", \"Onion\", \"Garlic\", \"Spices (cumin, coriander, paprika)\", \"Salt\", \"Pepper\"],\n",
        "      \"allergies\": {}\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Mujadara\",\n",
        "      \"ingredients\": [\"Lentils\", \"Rice\", \"Onions\", \"Olive oil\", \"Cumin\", \"Salt\", \"Pepper\"],\n",
        "      \"allergies\": {}\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Dolma\",\n",
        "      \"ingredients\": [\"Grape leaves\", \"Rice\", \"Ground meat\", \"Onion\", \"Tomato paste\", \"Spices (cinnamon, allspice)\", \"Lemon juice\"],\n",
        "      \"allergies\": {}\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Manakish\",\n",
        "      \"ingredients\": [\"Flatbread\", \"Za'atar\", \"Olive oil\", \"Cheese\", \"Meat (optional)\"],\n",
        "      \"allergies\": {\n",
        "        \"Gluten\": {\n",
        "          \"related_ingredient\": \"Flatbread\",\n",
        "          \"possible_symptoms\": [\"Bloating\", \"Diarrhea\", \"Fatigue\", \"Headaches\"],\n",
        "          \"caution\": \"Avoid if you have celiac disease or gluten intolerance.\"\n",
        "        },\n",
        "        \"Dairy\": {\n",
        "          \"related_ingredient\": \"Cheese\",\n",
        "          \"possible_symptoms\": [\"Hives\", \"Nausea\", \"Abdominal pain\", \"Anaphylaxis in severe cases\"],\n",
        "          \"caution\": \"Avoid if you have a dairy allergy or lactose intolerance.\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Kofta\",\n",
        "      \"ingredients\": [\"Ground meat (beef or lamb)\", \"Onion\", \"Garlic\", \"Parsley\", \"Spices (cumin, cinnamon)\", \"Salt\", \"Pepper\"],\n",
        "      \"allergies\": {}\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Sfeeha\",\n",
        "      \"ingredients\": [\"Ground meat\", \"Onions\", \"Tomato\", \"Pine nuts\", \"Spices (cinnamon, allspice)\", \"Dough\"],\n",
        "      \"allergies\": {\n",
        "        \"Nuts\": {\n",
        "          \"related_ingredient\": \"Pine nuts\",\n",
        "          \"possible_symptoms\": [\"Hives\", \"Swelling\", \"Nausea\", \"Anaphylaxis in severe cases\"],\n",
        "          \"caution\": \"Avoid if you have a nut allergy.\"\n",
        "        },\n",
        "        \"Gluten\": {\n",
        "          \"related_ingredient\": \"Dough\",\n",
        "          \"possible_symptoms\": [\"Bloating\", \"Diarrhea\", \"Fatigue\", \"Headaches\"],\n",
        "          \"caution\": \"Avoid if you have celiac disease or gluten intolerance.\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Labneh\",\n",
        "      \"ingredients\": [\"Yogurt\", \"Salt\", \"Olive oil\", \"Za'atar (optional)\"],\n",
        "      \"allergies\": {\n",
        "        \"Dairy\": {\n",
        "          \"related_ingredient\": \"Yogurt\",\n",
        "          \"possible_symptoms\": [\"Hives\", \"Nausea\", \"Abdominal pain\", \"Anaphylaxis in severe cases\"],\n",
        "          \"caution\": \"Avoid if you have a dairy allergy or lactose intolerance.\"\n",
        "        },\n",
        "        \"Sesame\": {\n",
        "          \"related_ingredient\": \"Za'atar\",\n",
        "          \"possible_symptoms\": [\"Hives\", \"Swelling\", \"Difficulty breathing\", \"Gastrointestinal issues\"],\n",
        "          \"caution\": \"Avoid if you have a sesame allergy.\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Baklava\",\n",
        "      \"ingredients\": [\"Phyllo pastry\", \"Nuts (walnuts, pistachios)\", \"Honey\", \"Sugar\", \"Butter\", \"Cinnamon\"],\n",
        "      \"allergies\": {\n",
        "        \"Nuts\": {\n",
        "          \"related_ingredient\": \"Walnuts, Pistachios\",\n",
        "          \"possible_symptoms\": [\"Hives\", \"Swelling\", \"Nausea\", \"Anaphylaxis in severe cases\"],\n",
        "          \"caution\": \"Avoid if you have a nut allergy.\"\n",
        "        },\n",
        "        \"Gluten\": {\n",
        "          \"related_ingredient\": \"Phyllo pastry\",\n",
        "          \"possible_symptoms\": [\"Bloating\", \"Diarrhea\", \"Fatigue\", \"Headaches\"],\n",
        "          \"caution\": \"Avoid if you have celiac disease or gluten intolerance.\"\n",
        "        },\n",
        "        \"Dairy\": {\n",
        "          \"related_ingredient\": \"Butter\",\n",
        "          \"possible_symptoms\": [\"Hives\", \"Nausea\", \"Abdominal pain\", \"Anaphylaxis in severe cases\"],\n",
        "          \"caution\": \"Avoid if you have a dairy allergy or lactose intolerance.\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Qatayef\",\n",
        "      \"ingredients\": [\"Flour\", \"Yeast\", \"Sugar\", \"Milk\", \"Nuts or cheese filling\", \"Syrup\"],\n",
        "      \"allergies\": {\n",
        "        \"Gluten\": {\n",
        "          \"related_ingredient\": \"Flour\",\n",
        "          \"possible_symptoms\": [\"Bloating\", \"Diarrhea\", \"Fatigue\", \"Headaches\"],\n",
        "          \"caution\": \"Avoid if you have celiac disease or gluten intolerance.\"\n",
        "        },\n",
        "        \"Dairy\": {\n",
        "          \"related_ingredient\": \"Milk, Cheese filling\",\n",
        "          \"possible_symptoms\": [\"Hives\", \"Nausea\", \"Abdominal pain\", \"Anaphylaxis in severe cases\"],\n",
        "          \"caution\": \"Avoid if you have a dairy allergy or lactose intolerance.\"\n",
        "        },\n",
        "        \"Nuts\": {\n",
        "          \"related_ingredient\": \"Nuts (if filled)\",\n",
        "          \"possible_symptoms\": [\"Hives\", \"Swelling\", \"Nausea\", \"Anaphylaxis in severe cases\"],\n",
        "          \"caution\": \"Avoid if you have a nut allergy.\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Harissa\",\n",
        "      \"ingredients\": [\"Chili peppers\", \"Garlic\", \"Cumin\", \"Coriander\", \"Olive oil\"],\n",
        "      \"allergies\": {}\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Biryani\",\n",
        "      \"ingredients\": [\"Rice\", \"Chicken or lamb\", \"Spices (saffron, cardamom)\", \"Onions\", \"Yogurt\", \"Mint\", \"Cilantro\"],\n",
        "      \"allergies\": {\n",
        "        \"Dairy\": {\n",
        "          \"related_ingredient\": \"Yogurt\",\n",
        "          \"possible_symptoms\": [\"Hives\", \"Nausea\", \"Abdominal pain\", \"Anaphylaxis in severe cases\"],\n",
        "          \"caution\": \"Avoid if you have a dairy allergy or lactose intolerance.\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Khobz\",\n",
        "      \"ingredients\": [\"Flour\", \"Water\", \"Yeast\", \"Salt\"],\n",
        "      \"allergies\": {\n",
        "        \"Gluten\": {\n",
        "          \"related_ingredient\": \"Flour\",\n",
        "          \"possible_symptoms\": [\"Bloating\", \"Diarrhea\", \"Fatigue\", \"Headaches\"],\n",
        "          \"caution\": \"Avoid if you have celiac disease or gluten intolerance.\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Kousa Mahshi\",\n",
        "      \"ingredients\": [\"Zucchini\", \"Rice\", \"Ground meat\", \"Tomato sauce\", \"Spices\", \"Onion\"],\n",
        "      \"allergies\": {}\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Bamya\",\n",
        "      \"ingredients\": [\"Okra\", \"Tomatoes\", \"Onion\", \"Garlic\", \"Lamb or beef\", \"Spices\", \"Olive oil\"],\n",
        "      \"allergies\": {}\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Feseekh\",\n",
        "      \"ingredients\": [\"Fermented fish\", \"Lemon\", \"Onion\", \"Salad\"],\n",
        "      \"allergies\": {\n",
        "        \"Fish\": {\n",
        "          \"related_ingredient\": \"Fermented fish\",\n",
        "          \"possible_symptoms\": [\"Hives\", \"Nausea\", \"Abdominal pain\", \"Anaphylaxis in severe cases\"],\n",
        "          \"caution\": \"Avoid if you have a fish allergy.\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Sambousek\",\n",
        "      \"ingredients\": [\"Dough\", \"Ground meat or cheese\", \"Onions\", \"Spices\", \"Oil for frying\"],\n",
        "      \"allergies\": {\n",
        "        \"Gluten\": {\n",
        "          \"related_ingredient\": \"Dough\",\n",
        "          \"possible_symptoms\": [\"Bloating\", \"Diarrhea\", \"Fatigue\", \"Headaches\"],\n",
        "          \"caution\": \"Avoid if you have celiac disease or gluten intolerance.\"\n",
        "        },\n",
        "        \"Dairy\": {\n",
        "          \"related_ingredient\": \"Cheese\",\n",
        "          \"possible_symptoms\": [\"Hives\", \"Nausea\", \"Abdominal pain\", \"Anaphylaxis in severe cases\"],\n",
        "          \"caution\": \"Avoid if you have a dairy allergy or lactose intolerance.\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Zaatar Manakish\",\n",
        "      \"ingredients\": [\"Flatbread\", \"Zaatar spice mix\", \"Olive oil\"],\n",
        "      \"allergies\": {\n",
        "        \"Gluten\": {\n",
        "          \"related_ingredient\": \"Flatbread\",\n",
        "          \"possible_symptoms\": [\"Bloating\", \"Diarrhea\", \"Fatigue\", \"Headaches\"],\n",
        "          \"caution\": \"Avoid if you have celiac disease or gluten intolerance.\"\n",
        "        },\n",
        "        \"Sesame\": {\n",
        "          \"related_ingredient\": \"Zaatar\",\n",
        "          \"possible_symptoms\": [\"Hives\", \"Swelling\", \"Difficulty breathing\", \"Gastrointestinal issues\"],\n",
        "          \"caution\": \"Avoid if you have a sesame allergy.\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Mansaf\",\n",
        "      \"ingredients\": [\"Lamb\", \"Rice\", \"Jameed (dried yogurt)\", \"Pine nuts\", \"Almonds\", \"Spices\"],\n",
        "      \"allergies\": {\n",
        "        \"Dairy\": {\n",
        "          \"related_ingredient\": \"Jameed\",\n",
        "          \"possible_symptoms\": [\"Hives\", \"Nausea\", \"Abdominal pain\", \"Anaphylaxis in severe cases\"],\n",
        "          \"caution\": \"Avoid if you have a dairy allergy.\"\n",
        "        },\n",
        "        \"Nuts\": {\n",
        "          \"related_ingredient\": \"Pine nuts, Almonds\",\n",
        "          \"possible_symptoms\": [\"Hives\", \"Swelling\", \"Nausea\", \"Anaphylaxis in severe cases\"],\n",
        "          \"caution\": \"Avoid if you have a nut allergy.\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Kousa Bil-Lahme\",\n",
        "      \"ingredients\": [\"Zucchini\", \"Ground beef\", \"Tomato sauce\", \"Onion\", \"Spices\", \"Rice\"],\n",
        "      \"allergies\": {}\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Tunisian Brik\",\n",
        "      \"ingredients\": [\"Brik pastry\", \"Tuna\", \"Capers\", \"Egg\", \"Parsley\", \"Lemon\"],\n",
        "      \"allergies\": {\n",
        "        \"Fish\": {\n",
        "          \"related_ingredient\": \"Tuna\",\n",
        "          \"possible_symptoms\": [\"Hives\", \"Nausea\", \"Abdominal pain\", \"Anaphylaxis in severe cases\"],\n",
        "          \"caution\": \"Avoid if you have a fish allergy.\"\n",
        "        },\n",
        "        \"Egg\": {\n",
        "          \"related_ingredient\": \"Egg\",\n",
        "          \"possible_symptoms\": [\"Hives\", \"Nausea\", \"Abdominal pain\", \"Anaphylaxis in severe cases\"],\n",
        "          \"caution\": \"Avoid if you have an egg allergy.\"\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Maqlooba\",\n",
        "      \"ingredients\": [\"Rice\", \"Chicken or lamb\", \"Eggplant\", \"Cauliflower\", \"Spices\", \"Tomato sauce\"],\n",
        "      \"allergies\": {}\n",
        "    }\n",
        "  ]\n"
      ],
      "metadata": {
        "id": "sEnTBj2RAl66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LlamaChatbot:\n",
        "    \"\"\"\n",
        "    A chatbot interface for generating conversational responses using the LLaMA language model.\n",
        "\n",
        "    Attributes:\n",
        "    - system_context (str): Contextual information to provide to the language model for all conversations.\n",
        "    - conversation_history (list of tuples): Stores the history of the conversation, where each\n",
        "      tuple contains a user message and the corresponding agent response.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, system_context):\n",
        "        \"\"\"\n",
        "        Initializes a new instance of the LlamaChatbot class.\n",
        "\n",
        "        Parameters:\n",
        "        - system_context (str): A string that sets the initial context for the language model.\n",
        "        \"\"\"\n",
        "        self.system_context = system_context\n",
        "        self.conversation_history = []  # Initializes the conversation history\n",
        "\n",
        "    def chat(self, user_msg):\n",
        "        \"\"\"\n",
        "        Generates a response from the chatbot based on the user's message.\n",
        "\n",
        "        This method constructs a prompt with the current system context and conversation history,\n",
        "        sends it to the language model, and then stores the new user message and model's response\n",
        "        in the conversation history.\n",
        "\n",
        "        Parameters:\n",
        "        - user_msg (str): The user's message to which the chatbot will respond.\n",
        "\n",
        "        Returns:\n",
        "        - str: The generated response from the chatbot.\n",
        "        \"\"\"\n",
        "        # Generate the prompt using the conversation history and the new user message\n",
        "        prompt = construct_prompt_with_context(user_msg, self.system_context, self.conversation_history)\n",
        "\n",
        "        # Get the model's response\n",
        "        agent_response = generate(prompt)\n",
        "\n",
        "        # Store this interaction in the conversation history\n",
        "        self.conversation_history.append((user_msg, agent_response))\n",
        "\n",
        "        return agent_response\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Resets the conversation history of the chatbot.\n",
        "\n",
        "        This method clears the existing conversation history, effectively restarting the conversation.\n",
        "        \"\"\"\n",
        "        # Clear conversation history\n",
        "        self.conversation_history = []"
      ],
      "metadata": {
        "id": "GyIxFk5XIfR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LlamaChatbotWithHistoryLimit:\n",
        "    \"\"\"\n",
        "    A chatbot interface for generating conversational responses using the LLaMA language model.\n",
        "\n",
        "    Attributes:\n",
        "        - system_context (str): Contextual information to provide to the language model for all conversations.\n",
        "        - conversation_history (list of tuples): Stores the history of the conversation, where each\n",
        "          tuple contains a user message and the corresponding agent response.\n",
        "        - tokenizer: The tokenizer used to tokenize the conversation for maintaining the history limit.\n",
        "        - max_tokens (int): The maximum number of tokens allowed in the conversation history.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, system_context, tokenizer, max_tokens=2048):\n",
        "        \"\"\"\n",
        "        Initializes a new instance of the LlamaChatbot class with a tokenizer and token limit.\n",
        "\n",
        "        Parameters:\n",
        "            - system_context (str): A string that sets the initial context for the language model.\n",
        "            - tokenizer: The tokenizer used to process the input and output for the language model.\n",
        "            - max_tokens (int): The maximum number of tokens to retain in the conversation history.\n",
        "        \"\"\"\n",
        "        self.system_context = system_context\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_tokens = max_tokens\n",
        "        self.conversation_history = []  # Initializes the conversation history\n",
        "\n",
        "    def chat(self, user_msg):\n",
        "        \"\"\"\n",
        "        Generates a response from the chatbot based on the user's message.\n",
        "\n",
        "        This method constructs a prompt with the current system context and conversation history,\n",
        "        sends it to the language model, and then stores the new user message and model's response\n",
        "        in the conversation history, ensuring that the history does not exceed the specified token limit.\n",
        "\n",
        "        Parameters:\n",
        "            - user_msg (str): The user's message to which the chatbot will respond.\n",
        "\n",
        "        Returns:\n",
        "            - str: The generated response from the chatbot.\n",
        "        \"\"\"\n",
        "        # Generate the prompt using the conversation history and the new user message\n",
        "        prompt = construct_prompt_with_context(user_msg, self.system_context, self.conversation_history)\n",
        "\n",
        "        # Get the model's response\n",
        "        agent_response = generate(prompt)\n",
        "\n",
        "        # Store this interaction in the conversation history\n",
        "        self.conversation_history.append((user_msg, agent_response))\n",
        "\n",
        "        # Check and maintain the conversation history within the token limit\n",
        "        self._trim_conversation_history()\n",
        "\n",
        "        return agent_response\n",
        "\n",
        "    def _trim_conversation_history(self):\n",
        "        \"\"\"\n",
        "        Trims the conversation history to maintain the number of tokens below the specified limit.\n",
        "        \"\"\"\n",
        "        # Concatenate the conversation history into a single string\n",
        "        history_string = ''.join(user + agent for user, agent in self.conversation_history)\n",
        "\n",
        "        # Calculate the number of tokens in the conversation history\n",
        "        history_tokens = len(self.tokenizer.encode(history_string))\n",
        "\n",
        "        # While the history exceeds the maximum token limit, remove the oldest items\n",
        "        while history_tokens > self.max_tokens:\n",
        "            # Always check if there's at least one item to pop\n",
        "            if self.conversation_history:\n",
        "                # Remove the oldest conversation tuple\n",
        "                self.conversation_history.pop(0)\n",
        "                # Recalculate the history string and its tokens\n",
        "                history_string = ''.join(user + agent for user, agent in self.conversation_history)\n",
        "                history_tokens = len(self.tokenizer.encode(history_string))\n",
        "            else:\n",
        "                # If the conversation history is empty, break out of the loop\n",
        "                break\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Resets the conversation history of the chatbot.\n",
        "\n",
        "        This method clears the existing conversation history, effectively restarting the conversation.\n",
        "        \"\"\"\n",
        "        # Clear conversation history\n",
        "        self.conversation_history = []"
      ],
      "metadata": {
        "id": "AaNBQojMC0jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_context = f\"\"\"\n",
        "You are a friendly chatbot knowledgeable about food , its ingredients and allergies {menu}. \\\n",
        "When asked about specific menu or ingredient, you try to provide accurate and helpful answers. \\\n",
        "Your goal is to assist and inform potential customers to the best of your ability in 50 words or less. \\\n",
        "You always end by asking what else you can help with.\n",
        "\"\"\"\n",
        "\n",
        "chatbot = LlamaChatbotWithHistoryLimit(system_context, tokenizer=tokenizer, max_tokens=200)"
      ],
      "metadata": {
        "id": "rPFo1EpADJxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_context = f\"\"\"\n",
        "You are a friendly chatbot knowledgeable about food , its ingredients and allergies {menu}. \\\n",
        "When asked about specific menu or ingredient, you try to provide accurate and helpful answers. \\\n",
        "Your goal is to assist and inform potential customers to the best of your ability in 50 words or less. \\\n",
        "You always end by asking what else you can help with.\n",
        "\"\"\"\n",
        "\n",
        "chatbot = LlamaChatbot(system_context)"
      ],
      "metadata": {
        "id": "HPcv9evSIn7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chatbot.chat(\" latest allergies in the menu?\"))"
      ],
      "metadata": {
        "id": "dlnMnuBwDzLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chatbot.chat(\"i have high sugar can u suggest a item?\"))"
      ],
      "metadata": {
        "id": "M6I9-EL-FtR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_token_count(concat_history(chatbot.conversation_history), tokenizer)"
      ],
      "metadata": {
        "id": "AekQirnFLYmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chatbot.chat(\"can i get a Baklava?\"))"
      ],
      "metadata": {
        "id": "ZOoasM55GFiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chatbot.chat(\"last week i had something with seasame which made me sick you know , i dont want get sick again\"))"
      ],
      "metadata": {
        "id": "aQMNrGhRG18_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chatbot.chat(\"im craving for a shawarma\"))"
      ],
      "metadata": {
        "id": "vttjb0TYHUds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chatbot.chat(\"and may be Zaatar Manakish followed by Baklava \"))\n"
      ],
      "metadata": {
        "id": "W0zvD26AHepk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chatbot.chat(\"Can you remind me of my allergies\"))\n"
      ],
      "metadata": {
        "id": "jl4AMPYFIGEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot.reset()"
      ],
      "metadata": {
        "id": "dssW_Imamaqe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}